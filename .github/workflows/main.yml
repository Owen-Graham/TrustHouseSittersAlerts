# .github/workflows/scrape.yml
name: Scrape TrustedHousesitters

on:
  push:
    branches:
      - main

  # Schedule to run every 15 minutes (UTC)
  schedule:
    - cron: '*/15 * * * *'

  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    env:
      TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
      TELEGRAM_CHAT_ID:  ${{ secrets.TELEGRAM_CHAT_ID }}
      THS_EMAIL:         ${{ secrets.THS_EMAIL }}
      THS_PASSWORD:      ${{ secrets.THS_PASSWORD }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright pandas requests python-dotenv
          playwright install

      - name: Run scraper
        run: python scraper.py

      - name: Upload debug artifacts
        if: failure()                        # only on error
        uses: actions/upload-artifact@v4     # publish artifacts
        with:
          name: scraper-debug                # artifact set name
          path: |
            login_debug.html                 # saved debug HTML
            login_debug.png                  # saved debug screenshot

      - name: Commit updated CSV/JSON
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add sits.csv sits.json
          if ! git diff --cached --quiet; then
            git commit -m 'chore: update sits.csv + sits.json [skip ci]'
            git push
          else
            echo "No changes to commit"
          fi
