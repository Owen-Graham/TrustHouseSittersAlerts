name: Scrape TrustedHousesitters

on:
  schedule:
    - cron: "0 * * * *"  # Every hour
  workflow_dispatch:      # Manual run button

permissions:
  contents: write         # Needed to commit data back to repo

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v3

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install --with-deps

      - name: ğŸ§¹ Run scraper
        run: python scraper.py
        env:
          THS_EMAIL: ${{ secrets.THS_EMAIL }}
          THS_PASSWORD: ${{ secrets.THS_PASSWORD }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}

      - name: ğŸ“¤ Commit and push if changed
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          git add sits.csv sits.json
          if ! git diff --cached --quiet; then
            git commit -m "ğŸ“ˆ Update sits.csv and sits.json from scraper"
            git push
          else
            echo "âœ… No changes to commit."

      - name: ğŸ“ Upload debug artifacts (if any)
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: login-debug
          path: |
            login_debug.png
            login_debug.html
          if-no-files-found: ignore
